{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "10Lk0lzWTP0az6mY2rsbe5_jt-jFyrNDO",
      "authorship_tag": "ABX9TyOLtMwBUmXPT1kod2Zs63c7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seungdo/translateMS/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MlwkZJf8kT_",
        "outputId": "4e89fcc1-105f-40dd-cd56-97e3e7fb8408"
      },
      "source": [
        "cd drive/MyDrive/Colab\\ Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4Ae0Lzm8p6V",
        "outputId": "95608e50-0cb7-42d3-f7cb-cd45547a2414"
      },
      "source": [
        "cd Peptide_Search-master/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Peptide_Search-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BnQGKNb8tEV",
        "outputId": "f9616637-871f-41ec-bfc3-5a38e1e7c485"
      },
      "source": [
        "!pip install tensorflow_text\n",
        "!pip install pyteomics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.6.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (2.6.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (5.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.39.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.37.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (2.6.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.12.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (2.6.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.4.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.34.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.5.0)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.6.0\n",
            "Collecting pyteomics\n",
            "  Downloading pyteomics-4.4.2-py2.py3-none-any.whl (196 kB)\n",
            "\u001b[K     |████████████████████████████████| 196 kB 8.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyteomics\n",
            "Successfully installed pyteomics-4.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX1lD6dR6L20"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, key의 문장 길이)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVbNEb4-6bi9"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def get_angles(position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    #tf.newaxis : expand dimensions\n",
        "    angle_rads = get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # list[<start>:<end>:<step>] even indices '0::2'\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # list[<start>:<end>:<step>] even indices '1::2'\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    angle_rads = np.zeros(angle_rads.shape)\n",
        "    angle_rads[:, 0::2] = sines\n",
        "    angle_rads[:, 1::2] = cosines\n",
        "    pos_encoding = tf.constant(angle_rads)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return look_ahead_mask\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead)\n",
        "    but it must be broadcastable for addition.\n",
        "    Args:\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: Float tensor with shape broadcastable\n",
        "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    Returns:\n",
        "    output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "\n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    return output, attention_weights\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    return out2\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    return out3, attn_weights_block1, attn_weights_block2\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, self.d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "    self.Dense = tf.keras.layers.Dense(units = self.d_model, activation = 'relu')\n",
        "\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate)\n",
        "                       for _ in range(num_layers)]\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x, y, training, mask):\n",
        "    \n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    y = tf.cast(y, tf.float32)\n",
        "    # z = y\n",
        "    # y = tf.keras.layers.Dense(units = 3, activation = tf.nn.sigmoid)(z)\n",
        "    # y = tf.convert_to_tensor([y])\n",
        "    # y = self.Dense(y)\n",
        "    # z = tf.concat([x,y], axis=1)\n",
        "    # for i in z:\n",
        "    #     for j in i:\n",
        "    #         j = tf.keras.layers.Dense(units=self.d_model, activation='relu')(j)\n",
        "    # print(z)\n",
        "\n",
        "    y = tf.repeat(y[:, :, tf.newaxis], self.d_model, axis=2)\n",
        "    # y = tf.keras.layers.Dense(units = 3, activation = tf.nn.sigmoid)(y)\n",
        "    # z = tf.concat([x,y], axis=1)\n",
        "    #print(y)\n",
        "    # y = self.Dense(y)\n",
        "    x = tf.math.multiply(x, y)\n",
        "    #tf.print(y)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "    return x  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               target_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
        "\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, dropout_rate)\n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x, enc_output, training,\n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "\n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "\n",
        "      attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "      attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights\n",
        "\n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size,target_vocab_size,\n",
        "               positional_encoding_input,positional_encoding_target,\n",
        "               dropout_rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
        "                             input_vocab_size,positional_encoding_input, dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
        "                           target_vocab_size, positional_encoding_target, dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, input, inten, target, training, enc_padding_mask,\n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "   \n",
        "    enc_output = self.encoder(input, inten, training, enc_padding_mask)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        target, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "    return final_output, attention_weights\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JF7ayho6cas"
      },
      "source": [
        "from numpy import asarray, zeros\n",
        "def vector_seq(sequences, dimension=10000):\n",
        "    results = zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "def normalize(arr, t_min, t_max):\n",
        "    norm_arr = []\n",
        "    diff = t_max - t_min\n",
        "    diff_arr = max(arr) - min(arr)\n",
        "    for i in arr:\n",
        "        temp = (((i - min(arr))*diff)/diff_arr) + t_min\n",
        "        norm_arr.append(temp)\n",
        "    return norm_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv63Ggbj6khq"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "def accuracy_function(real, pred):\n",
        "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
        "\n",
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 2nd attention block in the decoder.\n",
        "  # This padding mask is used to mask the encoder outputs.\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "  # Used in the 1st attention block in the decoder.\n",
        "  # It is used to pad and mask future tokens in the input received by\n",
        "  # the decoder.\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nft2XEWN6jsf"
      },
      "source": [
        "spectrum_feature_description = {\n",
        "    'inputs': tf.io.FixedLenSequenceFeature ([], tf.int64, allow_missing=True),\n",
        "    'intensity': tf.io.FixedLenSequenceFeature ([], tf.int64, allow_missing=True),\n",
        "    'outputs': tf.io.FixedLenSequenceFeature ([], tf.int64, allow_missing=True)\n",
        "}\n",
        "\n",
        "def _parse_spec_function(example_proto):\n",
        "    # Parse the input tf.Example proto using the dictionary above.\n",
        "    return tf.io.parse_single_example(example_proto, spectrum_feature_description)\n",
        "\n",
        "def input_fn(example_proto):\n",
        "    parsed_data=tf.io.parse_single_example(example_proto, spectrum_feature_description)\n",
        "    inputs = parsed_data['inputs']\n",
        "    intensity = parsed_data['intensity']\n",
        "    outputs  = parsed_data['outputs']\n",
        "    return inputs, intensity, outputs\n",
        "\n",
        "filename1 = \"train_dataset.tfrecords\"\n",
        "filename2 = \"valid_dataset.tfrecords\"\n",
        "# filename3 = \"train_dataset_oxi.tfrecords\"\n",
        "# filename4 = \"valid_dataset_oxi.tfrecords\"\n",
        "# list_of_tfrecord_train_files = [filename1, filename3]\n",
        "# list_of_tfrecord_valid_files = [filename2, filename4]\n",
        "train_dataset = tf.data.TFRecordDataset(filename1) \n",
        "valid_dataset = tf.data.TFRecordDataset(filename2) \n",
        "train_dataset = train_dataset.shuffle(400000)\n",
        "valid_dataset = valid_dataset.shuffle(50000)\n",
        "test_dataset = valid_dataset.take(7000)\n",
        "# full_dataset = input_fn(filename, batch_size=500, buffer_size=10)\n",
        "\n",
        "# dataset_size = 338976\n",
        "\n",
        "# train_size = int(0.9 * dataset_size)\n",
        "# test_size = int(0.1 * dataset_size)\n",
        "\n",
        "# # full_dataset = full_dataset.shuffle(buffer_size=1000000)\n",
        "# train_dataset = full_dataset.take(train_size)\n",
        "# valid_dataset = full_dataset.skip(train_size).take(test_size)\n",
        "\n",
        "# train_dataset = train_dataset.shuffle(300000)\n",
        "# valid_dataset = valid_dataset.shuffle(35000)\n",
        "# test_dataset = valid_dataset.skip(train_size).take(7000)\n",
        "#train_file = \"train.tfrecords\"\n",
        "#test_file = \"test.tfrecords\"\n",
        "\n",
        "# train_data = {}\n",
        "# for (batch, spec) in enumerate(train_dataset):\n",
        "#     input_raw = spec['inputs']\n",
        "#     intensity_raw = spec['intensity']\n",
        "#     output_raw = spec['outputs']\n",
        "#     train_data[batch] = {'inputs' : input_raw, 'intensity' : intensity_raw, 'outputs' : output_raw}\n",
        "    \n",
        "# test_data = {}\n",
        "# for (batch, spec) in enumerate(test_dataset):\n",
        "#     input_raw = spec['inputs']\n",
        "#     intensity_raw = spec['intensity']\n",
        "#     output_raw = spec['outputs']\n",
        "#     test_data[batch] = {'inputs' : input_raw, 'intensity' : intensity_raw, 'outputs' : output_raw}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C37BdbAU6qAA"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrX_k-IR6uoL"
      },
      "source": [
        "input_size = 500000\n",
        "dmodel = 64\n",
        "dff = 256\n",
        "num_layers = 2\n",
        "num_heads = 8\n",
        "dropout = 0.2\n",
        "output_size = 30\n",
        "BATCH_SIZE = 50\n",
        "BUFFER_SIZE = 60000\n",
        "\n",
        "train_dataset = (train_dataset\n",
        "                 .map(input_fn)\n",
        "                 .padded_batch(BATCH_SIZE)\n",
        "                 .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "valid_dataset = (valid_dataset\n",
        "                 .map(input_fn)\n",
        "                 .padded_batch(BATCH_SIZE)\n",
        "                 .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "test_dataset = (test_dataset\n",
        "                .map(input_fn)\n",
        "                .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=dmodel,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=input_size,\n",
        "    target_vocab_size=output_size,\n",
        "    positional_encoding_input = 2000,\n",
        "    positional_encoding_target = 50,\n",
        "    dropout_rate=dropout)\n",
        "\n",
        "learning_rate = CustomSchedule(dmodel)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "# checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "# ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "#                            optimizer=optimizer)\n",
        "\n",
        "# ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# # if a checkpoint exists, restore the latest checkpoint.\n",
        "# if ckpt_manager.latest_checkpoint:\n",
        "#   ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "#   print('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6cp2fIu6y9v"
      },
      "source": [
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, inten, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, inten, tar_inp,\n",
        "                                 True,\n",
        "                                 enc_padding_mask,\n",
        "                                 combined_mask,\n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(accuracy_function(tar_real, predictions))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2d48vBQnsWy"
      },
      "source": [
        "def evaluate(dataset, max_length=40):\n",
        "    total =0\n",
        "    count = 0\n",
        "    for (inputs, intensity, outputs) in dataset:\n",
        "      start = 1\n",
        "      end = 2\n",
        "      total+=1\n",
        "      sequence = outputs\n",
        "\n",
        "      input = tf.convert_to_tensor([inputs])\n",
        "      inten = tf.convert_to_tensor([intensity])\n",
        "      \n",
        "      output = tf.convert_to_tensor([start],dtype=tf.int64)\n",
        "      output = tf.expand_dims(output, 0)\n",
        "\n",
        "      if(total % 200 == 0):\n",
        "          print(f'Peptide accuracy is :{count/total:.4f}')\n",
        "      \n",
        "      for i in range(max_length):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            input, output)\n",
        "       \n",
        "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "        predictions, attention_weights = transformer(input,\n",
        "                                                     inten,\n",
        "                                                     output,\n",
        "                                                     False,\n",
        "                                                     enc_padding_mask,\n",
        "                                                     combined_mask,\n",
        "                                                     dec_padding_mask)\n",
        "        \n",
        "        # select the last word from the seq_len dimension\n",
        "        predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "        predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "        # return the result if the predicted_id is equal to the end token\n",
        "        if predicted_id == end and len(output[0]) == len(sequence):\n",
        "            if tf.reduce_all(output == sequence):\n",
        "                    count+=1\n",
        "            break\n",
        "\n",
        "    return count/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bouHZACBo9o7"
      },
      "source": [
        "def validation(dataset):\n",
        "    accuracy = 0\n",
        "    cnt = 0\n",
        "    for batch, (input, inten, output) in enumerate(dataset):\n",
        "        dec_input = output[:, :-1]\n",
        "        target_real = output[:, 1:]\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(input, dec_input)\n",
        "\n",
        "        predictions, _ = transformer(input, inten, dec_input,\n",
        "                                   False,\n",
        "                                   enc_padding_mask,\n",
        "                                   combined_mask,\n",
        "                                   dec_padding_mask)\n",
        "\n",
        "        accuracy += accuracy_function(target_real, predictions)\n",
        "        cnt = batch+1\n",
        "\n",
        "    return accuracy / cnt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmxjGAD3QF5W",
        "outputId": "0b9f669f-9f44-48b8-a26e-04ca4733c753"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "   ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "   print('Latest checkpoint restored!!') \n",
        "\n",
        "# print(f'peptide level accuracy: {evaluate(test_dataset):.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest checkpoint restored!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxVJzjCZ61Ih",
        "outputId": "23edf959-6453-43eb-f09b-0b6ebb8c38d3"
      },
      "source": [
        "epoch = 0\n",
        "while True:\n",
        "  start = time.time()\n",
        "\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "\n",
        "  # inp -> portuguese, tar -> english\n",
        "  for batch, (input, intensity, output) in enumerate(train_dataset):\n",
        "    train_step(input, intensity, output)\n",
        "    # print(input.shape)\n",
        "    # if batch % 50 == 0:\n",
        "    #     print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "     ckpt_save_path = ckpt_manager.save()\n",
        "     print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
        "\n",
        "  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "  valid_accuracy = validation(valid_dataset)\n",
        "  print(\"validation Accuracy: {:.4f}\".format(valid_accuracy))\n",
        "\n",
        "  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n",
        "\n",
        "  epoch += 1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 1.3948 Accuracy 0.5589\n",
            "validation Accuracy: 0.5299\n",
            "Time taken for 1 epoch: 1455.70 secs\n",
            "\n",
            "Epoch 2 Loss 1.3929 Accuracy 0.5592\n",
            "validation Accuracy: 0.5284\n",
            "Time taken for 1 epoch: 1382.72 secs\n",
            "\n",
            "Epoch 3 Loss 1.3936 Accuracy 0.5592\n",
            "validation Accuracy: 0.5296\n",
            "Time taken for 1 epoch: 1381.83 secs\n",
            "\n",
            "Epoch 4 Loss 1.3935 Accuracy 0.5591\n",
            "validation Accuracy: 0.5242\n",
            "Time taken for 1 epoch: 1380.40 secs\n",
            "\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-39\n",
            "Epoch 5 Loss 1.3920 Accuracy 0.5598\n",
            "validation Accuracy: 0.5302\n",
            "Time taken for 1 epoch: 1381.92 secs\n",
            "\n",
            "Epoch 6 Loss 1.3905 Accuracy 0.5601\n",
            "validation Accuracy: 0.5318\n",
            "Time taken for 1 epoch: 1376.42 secs\n",
            "\n",
            "Epoch 7 Loss 1.3903 Accuracy 0.5601\n",
            "validation Accuracy: 0.5320\n",
            "Time taken for 1 epoch: 1377.20 secs\n",
            "\n",
            "Epoch 8 Loss 1.3899 Accuracy 0.5600\n",
            "validation Accuracy: 0.5322\n",
            "Time taken for 1 epoch: 1376.97 secs\n",
            "\n",
            "Epoch 9 Loss 1.3889 Accuracy 0.5603\n",
            "validation Accuracy: 0.5308\n",
            "Time taken for 1 epoch: 1374.19 secs\n",
            "\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-40\n",
            "Epoch 10 Loss 1.3896 Accuracy 0.5600\n",
            "validation Accuracy: 0.5330\n",
            "Time taken for 1 epoch: 1379.53 secs\n",
            "\n",
            "Epoch 11 Loss 1.3898 Accuracy 0.5600\n",
            "validation Accuracy: 0.5279\n",
            "Time taken for 1 epoch: 1375.88 secs\n",
            "\n",
            "Epoch 12 Loss 1.3895 Accuracy 0.5600\n",
            "validation Accuracy: 0.5290\n",
            "Time taken for 1 epoch: 1379.01 secs\n",
            "\n",
            "Epoch 13 Loss 1.3885 Accuracy 0.5604\n",
            "validation Accuracy: 0.5280\n",
            "Time taken for 1 epoch: 1376.60 secs\n",
            "\n",
            "Epoch 14 Loss 1.3870 Accuracy 0.5611\n",
            "validation Accuracy: 0.5327\n",
            "Time taken for 1 epoch: 1377.66 secs\n",
            "\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-41\n",
            "Epoch 15 Loss 1.3873 Accuracy 0.5608\n",
            "validation Accuracy: 0.5325\n",
            "Time taken for 1 epoch: 1382.91 secs\n",
            "\n",
            "Epoch 16 Loss 1.3870 Accuracy 0.5611\n",
            "validation Accuracy: 0.5334\n",
            "Time taken for 1 epoch: 1375.41 secs\n",
            "\n",
            "Epoch 17 Loss 1.3862 Accuracy 0.5613\n",
            "validation Accuracy: 0.5324\n",
            "Time taken for 1 epoch: 1375.19 secs\n",
            "\n",
            "Epoch 18 Loss 1.3849 Accuracy 0.5615\n",
            "validation Accuracy: 0.5312\n",
            "Time taken for 1 epoch: 1379.91 secs\n",
            "\n",
            "Epoch 19 Loss 1.3852 Accuracy 0.5614\n",
            "validation Accuracy: 0.5260\n",
            "Time taken for 1 epoch: 1378.55 secs\n",
            "\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-42\n",
            "Epoch 20 Loss 1.3844 Accuracy 0.5619\n",
            "validation Accuracy: 0.5296\n",
            "Time taken for 1 epoch: 1381.77 secs\n",
            "\n",
            "Epoch 21 Loss 1.3838 Accuracy 0.5622\n",
            "validation Accuracy: 0.5271\n",
            "Time taken for 1 epoch: 1379.72 secs\n",
            "\n",
            "Epoch 22 Loss 1.3836 Accuracy 0.5625\n",
            "validation Accuracy: 0.5314\n",
            "Time taken for 1 epoch: 1381.42 secs\n",
            "\n",
            "Epoch 23 Loss 1.3833 Accuracy 0.5624\n",
            "validation Accuracy: 0.5254\n",
            "Time taken for 1 epoch: 1378.23 secs\n",
            "\n",
            "Epoch 24 Loss 1.3824 Accuracy 0.5628\n",
            "validation Accuracy: 0.5257\n",
            "Time taken for 1 epoch: 1378.76 secs\n",
            "\n",
            "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-43\n",
            "Epoch 25 Loss 1.3821 Accuracy 0.5626\n",
            "validation Accuracy: 0.5297\n",
            "Time taken for 1 epoch: 1379.82 secs\n",
            "\n",
            "Epoch 26 Loss 1.3820 Accuracy 0.5626\n",
            "validation Accuracy: 0.5322\n",
            "Time taken for 1 epoch: 1377.13 secs\n",
            "\n",
            "Epoch 27 Loss 1.3815 Accuracy 0.5629\n",
            "validation Accuracy: 0.5328\n",
            "Time taken for 1 epoch: 1380.09 secs\n",
            "\n",
            "Epoch 28 Loss 1.3808 Accuracy 0.5632\n",
            "validation Accuracy: 0.5332\n",
            "Time taken for 1 epoch: 1382.43 secs\n",
            "\n",
            "Epoch 29 Loss 1.3816 Accuracy 0.5628\n",
            "validation Accuracy: 0.5314\n",
            "Time taken for 1 epoch: 1377.18 secs\n",
            "\n",
            "Saving checkpoint for epoch 30 at ./checkpoints/train/ckpt-44\n",
            "Epoch 30 Loss 1.3805 Accuracy 0.5631\n",
            "validation Accuracy: 0.5382\n",
            "Time taken for 1 epoch: 1382.88 secs\n",
            "\n",
            "Epoch 31 Loss 1.3792 Accuracy 0.5635\n",
            "validation Accuracy: 0.5311\n",
            "Time taken for 1 epoch: 1374.27 secs\n",
            "\n",
            "Epoch 32 Loss 1.3795 Accuracy 0.5635\n",
            "validation Accuracy: 0.5316\n",
            "Time taken for 1 epoch: 1375.41 secs\n",
            "\n",
            "Epoch 33 Loss 1.3799 Accuracy 0.5635\n",
            "validation Accuracy: 0.5371\n",
            "Time taken for 1 epoch: 1375.78 secs\n",
            "\n",
            "Epoch 34 Loss 1.3793 Accuracy 0.5637\n",
            "validation Accuracy: 0.5289\n",
            "Time taken for 1 epoch: 1378.21 secs\n",
            "\n",
            "Saving checkpoint for epoch 35 at ./checkpoints/train/ckpt-45\n",
            "Epoch 35 Loss 1.3780 Accuracy 0.5643\n",
            "validation Accuracy: 0.5372\n",
            "Time taken for 1 epoch: 1380.59 secs\n",
            "\n",
            "Epoch 36 Loss 1.3776 Accuracy 0.5643\n",
            "validation Accuracy: 0.5345\n",
            "Time taken for 1 epoch: 1378.07 secs\n",
            "\n",
            "Epoch 37 Loss 1.3785 Accuracy 0.5639\n",
            "validation Accuracy: 0.5328\n",
            "Time taken for 1 epoch: 1378.54 secs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fshEz3TqGCKD"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "   ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "   print('Latest checkpoint restored!!') \n",
        "\n",
        "print(f'peptide level accuracy: {evaluate(test_dataset):.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jABPR07063uF"
      },
      "source": [
        "# def evaluate(dataset, max_length=40):\n",
        "#     cnt_total =0\n",
        "#     cnt_correct = 0\n",
        "#     for (inputs, intensity, outputs) in dataset:\n",
        "#       input = inputs['inputs']\n",
        "#       inten = intensity['intensity']\n",
        "#       sequence = outputs['outputs']\n",
        "#       start = 1\n",
        "#       end = 2\n",
        "\n",
        "#       input = tf.convert_to_tensor([input])\n",
        "#       inten = tf.convert_to_tensor([inten])\n",
        "#       output = tf.convert_to_tensor([start])\n",
        "#       output = tf.expand_dims(output, 0)\n",
        "      \n",
        "#       for i in range(max_length):\n",
        "#         enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "#             input, output)\n",
        "       \n",
        "#         # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "#         predictions, attention_weights = transformer(input,\n",
        "#                                                      inten,\n",
        "#                                                      output,\n",
        "#                                                      False,\n",
        "#                                                      enc_padding_mask,\n",
        "#                                                      combined_mask,\n",
        "#                                                      dec_padding_mask)\n",
        "        \n",
        "#         # select the last word from the seq_len dimension\n",
        "#         predictions = predictions[:, -1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "#         predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "#         # concatentate the predicted_id to the output which is given to the decoder\n",
        "#         # as its input.\n",
        "#         output = tf.cast(output, tf.int64) \n",
        "#         output = tf.concat([output, predicted_id], axis=-1)\n",
        "#         print(output)\n",
        "#         print(sequence)\n",
        "#         # return the result if the predicted_id is equal to the end token\n",
        "#         if predicted_id == end:\n",
        "#             if tf.reduce_all(output == sequence):\n",
        "#                     cnt_correct+=1\n",
        "#             break\n",
        "\n",
        "#     return cnt_correct/cnt_total\n",
        "\n",
        "# print(f'Accuracy of test data for peptide level : {evaluate(test_data):.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRlcvMHTS1au",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2725699d-f88b-4f38-e073-486b3fe5c465"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch master\n",
            "\n",
            "No commits yet\n",
            "\n",
            "Changes to be committed:\n",
            "  (use \"git rm --cached <file>...\" to unstage)\n",
            "\n",
            "\t\u001b[32mnew file:   README.md\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31m.idea/\u001b[m\n",
            "\t\u001b[31m__pycache__/\u001b[m\n",
            "\t\u001b[31mcheckpoints/\u001b[m\n",
            "\t\u001b[31mexcept_Oxi.tfrecords\u001b[m\n",
            "\t\u001b[31mmgf_data.tfrecords\u001b[m\n",
            "\t\u001b[31mmsms.tfrecords\u001b[m\n",
            "\t\u001b[31mtrain_dataset.tfrecords\u001b[m\n",
            "\t\u001b[31mtrain_dataset_oxi.tfrecords\u001b[m\n",
            "\t\u001b[31mvalid_dataset.tfrecords\u001b[m\n",
            "\t\u001b[31mvalid_dataset_oxi.tfrecords\u001b[m\n",
            "\n"
          ]
        }
      ]
    }
  ]
}